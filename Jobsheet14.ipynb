{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUS1PZDvHIglbXPkDDOdUR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DandyWs/Jobsheet1/blob/main/Jobsheet14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kecerdasan Buatan**\n",
        "## Laporan Jobsheet Pertemuan 12\n",
        "### Nama : Dandy Wahyu Syahputra\n",
        "### NIM : 2141720002\n",
        "### Absen / Kelas : 08 / TI - 2C\n",
        "### Link Github : "
      ],
      "metadata": {
        "id": "xn9lVzmsp77q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Praktikum Decision Tree"
      ],
      "metadata": {
        "id": "GD9o2gA1cIBC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QPw33-9zb8tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58de7b22-93ab-44d8-a15d-b6cc7f63e169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9402859586706309"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "eps = np.finfo(float).eps\n",
        "from numpy import log2 as log\n",
        "\n",
        "outlook = 'overcast,overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')\n",
        "temp = 'hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')\n",
        "humadity = 'high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,normal'.split(',')\n",
        "windy = 'FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')\n",
        "play = 'yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')\n",
        "\n",
        "dataset = {'outlook':outlook,'temp':temp,'humadity':humadity,'windy':windy,'play':play}\n",
        "df = pd.DataFrame(dataset,columns=['outlook','temp','humadity','windy','play'])\n",
        "\n",
        "entropy_node = 0\n",
        "values = df.play.unique()\n",
        "for value in values:\n",
        "    fraction = df.play.value_counts()[value]/len(df.play)\n",
        "    entropy_node += -fraction*np.log2(fraction)\n",
        "entropy_node"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ent(df,attribute):\n",
        "    target_variables = df.play.unique()\n",
        "    variables = df[attribute].unique()\n",
        "\n",
        "    entropy_attribute = 0\n",
        "    for variable in variables:\n",
        "        entropy_each_feature =0\n",
        "        for target_variable in target_variables:\n",
        "            num=len(df[attribute][df[attribute]==variable][df.play==target_variable])\n",
        "            den=len(df[attribute][df[attribute]==variable])\n",
        "            fraction = num/(den+eps)\n",
        "            entropy_each_feature += -fraction*log(fraction+eps)\n",
        "        fraction2 = den/len(df)\n",
        "        entropy_attribute += -fraction2*entropy_each_feature\n",
        "\n",
        "    return(abs(entropy_attribute))\n",
        "\n",
        "a_entropy = {k:ent(df,k) for k in df.keys()[:-1]}\n",
        "a_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V__GkhZ8oXJV",
        "outputId": "9f0de02d-b4d0-4b65-cf1d-cc1624277431"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'outlook': 0.6935361388961914,\n",
              " 'temp': 0.9110633930116756,\n",
              " 'humadity': 0.7884504573082889,\n",
              " 'windy': 0.892158928262361}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ig(e_dataset,e_attr):\n",
        "  return(e_dataset-e_attr)"
      ],
      "metadata": {
        "id": "Bmjx72Vrme2X"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IG = {k:ig(entropy_node,a_entropy[k]) for k in a_entropy}\n",
        "IG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FudOYxyNmuvF",
        "outputId": "f9117ea0-5f23-4559-bb3f-d8295ab72036"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'outlook': 0.24674981977443955,\n",
              " 'temp': 0.029222565658955313,\n",
              " 'humadity': 0.15183550136234203,\n",
              " 'windy': 0.04812703040826993}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Complete Code"
      ],
      "metadata": {
        "id": "IsZFO7rNnF6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "eps = np.finfo(float).eps\n",
        "from numpy import log2 as log\n",
        "\n",
        "# Data\n",
        "outlook = 'overcast,overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')\n",
        "temp = 'hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')\n",
        "humidity = 'high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,norma'.split(',')\n",
        "windy = 'FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')\n",
        "play = 'yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')\n",
        "\n",
        "# Membuat Data Frame\n",
        "dataset ={'outlook':outlook,'temp':temp,'humidity':humidity,'windy':windy,'play':play}\n",
        "df = pd.DataFrame(dataset,columns=['outlook','temp','humidity','windy','play'])\n",
        "\n",
        "def find_entropy(df):\n",
        "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
        "    entropy = 0\n",
        "    values = df[Class].unique()\n",
        "    for value in values:\n",
        "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
        "        entropy += -fraction*np.log2(fraction)\n",
        "    return entropy\n",
        "\n",
        "def find_entropy_attribute(df,attribute):\n",
        "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
        "    target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
        "    variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
        "    entropy2 = 0\n",
        "    for variable in variables:\n",
        "        entropy = 0\n",
        "        for target_variable in target_variables:\n",
        "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
        "            den = len(df[attribute][df[attribute]==variable])\n",
        "            fraction = num/(den+eps)  #pi\n",
        "            entropy += -fraction*log(fraction+eps) #This calculates entropy for one feature like 'Hot'\n",
        "        fraction2 = den/len(df)\n",
        "        entropy2 += -fraction2*entropy   #Sums up all the entropy ETaste\n",
        "    return abs(entropy2)\n",
        "\n",
        "def find_winner(df):\n",
        "    Entropy_att = []\n",
        "    IG = []\n",
        "    for key in df.keys()[:-1]:\n",
        "        #entropy_att.append(find_entropy_attribute(df,key))\n",
        "      IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
        "    return df.keys()[:-1][np.argmax(IG)]\n",
        "\n",
        "def get_subtable(df, node,value):\n",
        "    return df[df[node] == value].reset_index(drop=True)\n",
        "\n",
        "def buildTree(df,tree=None):\n",
        "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
        "    # Get attribute with maximum information gain\n",
        "    node = find_winner(df)\n",
        "    #Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
        "    attValue = np.unique(df[node])\n",
        "    #Create an empty dictionary to create tree\n",
        "    if tree is None:\n",
        "        tree={}\n",
        "        tree[node] = {}\n",
        "\n",
        "    #We make loop to construct a tree by calling this function recursively.\n",
        "    #In this we check if the subset is pure and stops if it is pure.\n",
        "    for value in attValue:\n",
        "        subtable = get_subtable(df,node,value)\n",
        "        clValue,counts = np.unique(subtable['play'],return_counts=True)\n",
        "        if len(counts)==1:#Checking purity of subset\n",
        "            tree[node][value] = clValue[0]\n",
        "        else:\n",
        "            tree[node][value] = buildTree(subtable) \n",
        "\n",
        "    return tree"
      ],
      "metadata": {
        "id": "3G4IbcFgnIxD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####install pprintpp\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZSRsQ9UenrH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pprintpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kfA4yJgnuOK",
        "outputId": "905321b5-b597-437c-a9aa-b7b0c4aa8e76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pprintpp\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: pprintpp\n",
            "Successfully installed pprintpp-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####code running"
      ],
      "metadata": {
        "id": "BbmmFwIXn4Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = buildTree(df)\n",
        "import pprint\n",
        "pprint.pprint(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyya05vrn55T",
        "outputId": "f575ba21-e75d-472c-b871-b3822837cf53"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'outlook': {'overcast': 'yes',\n",
            "             'rainy': {'windy': {'FALSE': 'yes', 'TRUE': 'no'}},\n",
            "             'sunny': {'humidity': {'high': 'no',\n",
            "                                    'norma': 'yes',\n",
            "                                    'normal': 'yes'}}}}\n"
          ]
        }
      ]
    }
  ]
}